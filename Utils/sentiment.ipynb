{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a748e5",
   "metadata": {},
   "source": [
    "# Sentiment analysis on document level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f820dd",
   "metadata": {},
   "source": [
    "## Base Line for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd53c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbischoff/Documents/MasterInformatik/MSE/Best-search-engine-in-the-world/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8385c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95a4dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"Feuerzangenbowle (German: is a traditional German alcoholic drink for which a rum-soaked sugarloaf is set on fire and drips into mulled wine. It is often part of a Christmas or New Year's Eve tradition. The name translates literally as fire-tongs punch, Bowle meaning punch being borrowed from English.The popularity of the drink was boosted in Germany by the 1944 comedy film Die Feuerzangenbowle. It is a traditional drink of some German fraternities, who also call it Krambambuli, as the red color is reminiscent of a cherry liqueur of that name which was manufactured by the distillery Der Lachs zu Danzig [de] (in Gdańsk).[1][2]Procedure Feuerzangenbowle is prepared in a bowl, similar to a fondue set, which usually is suspended over a small burner (Rechaud). The bowl is filled with heated dry red wine spiced with cinnamon sticks, cloves, star anise and orange peel, similar to mulled wine. The Feuerzange was originally a pair of tongs, but nowadays it is common for a purpose-designed metal grate mounted on top of the bowl to hold the Zuckerhut (sugarloaf), a 250-gram (9 oz) lump of sugar. The sugar is soaked with rum and set alight, melting and caramelizing. The rum should have at least 54% alcohol by volume (ABV), such as the high-ABV Austrian rum Stroh 80, and be at room temperature in order to burn properly. More rum is poured with a ladle until all the sugar has melted and mixed with the wine. The resulting punch is served in mugs while the burner keeps the bowl warm. For some the ceremony is more important than the drink itself, celebrating the gathering of friends and conveying a notion of Gemütlichkeit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d99df2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from a file as junks inta array\n",
    "\n",
    "def load_data_as_chunks(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "    return [line.strip() for line in data if line.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "398df5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a90deb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(tokens, chunk_size=400):\n",
    "    return [' '.join(tokens[i:i+chunk_size]) for i in range(0, len(tokens), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94e1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6900f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = join_data(data.split(), chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ea3447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def document_sentiment_analysis_binary(data : list[str], pipeline=sentiment_pipeline, seed= 0, random_aprox=False):\n",
    "\n",
    "    doc_analysis = {}\n",
    "\n",
    "    if random_aprox:\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        # natural random numbers for testing\n",
    "        random_scores = np.unique(np.random.randint(0, len(data), 10))\n",
    "        data = [test_data[i] for i in random_scores]\n",
    "\n",
    "    analysis = pipeline(data)\n",
    "\n",
    "    if analysis[\"label\" == \"NEGATIVE\"] != None:\n",
    "        negative_prob = np.sum([doc_analysis[\"score\"] for doc_analysis in analysis if doc_analysis[\"label\"] == \"NEGATIVE\" ]) / len(analysis)\n",
    "    else:\n",
    "        negative_prob = 0\n",
    "    if analysis[\"label\" == \"POSITIVE\"] != None:\n",
    "        positive_prob = np.sum([doc_analysis[\"score\"] for doc_analysis in analysis if doc_analysis[\"label\"] == \"POSITIVE\" ])  / len(analysis)\n",
    "    else:\n",
    "        positive_prob = 0\n",
    "\n",
    "    if negative_prob > positive_prob:\n",
    "        doc_analysis[\"label\"] = \"NEGATIVE\"\n",
    "        doc_analysis[\"score\"] = negative_prob\n",
    "    else:\n",
    "        doc_analysis[\"label\"] = \"POSITIVE\"\n",
    "        doc_analysis[\"score\"] = positive_prob\n",
    "\n",
    "    return doc_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "293c424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0af991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.7614216804504395}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1fa6512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE', 'score': 0.7614216804504395}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_sentiment_analysis_binary(test_data, random_aprox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae8a0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"I love you. I hate you. I am indifferent to you. You are the best thing that ever happened to me. You are the worst thing that ever happened to me. I am neutral about you. You make me happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "37c4cffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'NEGATIVE', 'score': 0.46918564372592503}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# subjectivity detection in newspaper sentences\n",
    "# A sentence is subjective if its content is based on or influenced by personal feelings, tastes, or opinions. Otherwise, the sentence is objective. (Antici et al., 2023).\n",
    "# https://huggingface.co/GroNLP/mdebertav3-subjectivity-english\n",
    "# https://checkthat.gitlab.io/clef2023/task2/\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"GroNLP/mdebertav3-subjectivity-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62c78437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_sentiment_analysis(data : list[str]):\n",
    "\n",
    "    doc_analysis = {}\n",
    "    analysis = sentiment_pipeline(data)\n",
    "\n",
    "    unique_labels = np.unique([doc[\"label\"] for doc in analysis])\n",
    "\n",
    "    arg_max_labels = 0\n",
    "\n",
    "    for label in unique_labels:\n",
    "\n",
    "        label_prob = np.sum([doc_analysis[\"score\"] for doc_analysis in analysis if doc_analysis[\"label\"] == label ]) / len(analysis)\n",
    "\n",
    "        if arg_max_labels < label_prob:\n",
    "            doc_analysis[\"label\"] = label\n",
    "            doc_analysis[\"score\"] = label_prob\n",
    "\n",
    "    return doc_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a74ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielbischoff/Documents/MasterInformatik/MSE/Best-search-engine-in-the-world/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/mdebertav3-subjectivity-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"GroNLP/mdebertav3-subjectivity-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a6549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"GroNLP/mdebertav3-subjectivity-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8202b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def document_sentiment_analysis_binary(data: list[str], pipeline, seed=0, random_aprox=False):\n",
    "    # Optional approximation using random chunks\n",
    "    if random_aprox:\n",
    "        random.seed(seed)\n",
    "        if len(data) > 10:\n",
    "            data = random.sample(data, 10)\n",
    "\n",
    "    # Run the sentiment pipeline (batched)\n",
    "    analysis = pipeline(data)\n",
    "\n",
    "    # Group scores by label\n",
    "    objective_scores = [entry[\"score\"] for entry in analysis if entry[\"label\"] == \"LABEL_0\"]\n",
    "    subjective_scores = [entry[\"score\"] for entry in analysis if entry[\"label\"] == \"LABEL_1\"]\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_objective = sum(objective_scores) / len(objective_scores) if objective_scores else 0\n",
    "    avg_subjective = sum(subjective_scores) / len(subjective_scores) if subjective_scores else 0\n",
    "\n",
    "    # Determine dominant label\n",
    "    if avg_subjective >= avg_objective:\n",
    "        return {\"label\": \"subjective\", \"score\": avg_subjective}\n",
    "    else:\n",
    "        return {\"label\": \"objective\", \"score\": avg_objective}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31bf45ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'subjective', 'score': 0.770626425743103}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_sentiment_analysis_binary(data, pipe, random_aprox=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
